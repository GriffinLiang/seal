{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329b9fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "\n",
    "data_path = '../data/VAW/clean_data'\n",
    "\n",
    "with open(osp.join(data_path, 'object_index.json')) as f:\n",
    "    object_index = json.load(f)\n",
    "    \n",
    "with open(osp.join(data_path, 'attribute_index.json')) as f:\n",
    "    attribute_index = json.load(f)\n",
    "\n",
    "object_index_reversed = {v:k for k, v in object_index.items()}\n",
    "attribute_index_reversed = {v:k for k, v in attribute_index.items()}\n",
    "\n",
    "anno = {}\n",
    "for stage in ['train', 'val', 'test']:\n",
    "    with open(osp.join(data_path, '{}.json'.format(stage))) as f:\n",
    "        anno[stage] = json.load(f)\n",
    "\n",
    "num_obj = len(object_index)\n",
    "num_att = len(attribute_index)\n",
    "print(num_obj, num_att)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3942ace2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_num(anno_list, num_obj, num_att):\n",
    "    obj_att_anno = np.zeros((num_obj, num_att))\n",
    "    for anno_image in anno_list:\n",
    "        object_name = anno_image['object_name']\n",
    "        positive_attributes = anno_image['positive_attributes']\n",
    "        negative_attributes = anno_image['negative_attributes']\n",
    "        object_index_image = object_index[object_name]\n",
    "        anno_attributes = positive_attributes + negative_attributes\n",
    "        for att in anno_attributes:\n",
    "            attribute_index_image = attribute_index[att]\n",
    "            obj_att_anno[object_index_image, attribute_index_image] += 1\n",
    "    return obj_att_anno\n",
    "\n",
    "obj_att_anno = calculate_num(\n",
    "    anno['train']+anno['val'], num_obj, num_att\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242da124",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_id = np.random.randint(num_obj)\n",
    "print('OBJ: ', object_index_reversed[obj_id])\n",
    "\n",
    "def find_feasible_attribute(obj_att_anno, obj_id):\n",
    "    att_vec = obj_att_anno[obj_id]\n",
    "    feasible_attributes = np.where(att_vec > 0)[0]\n",
    "    feasible_attribute_names = []\n",
    "    for a in feasible_attributes:\n",
    "        feasible_attribute_names.append(attribute_index_reversed[a])\n",
    "    return feasible_attribute_names\n",
    "\n",
    "feasible_attribute_names = find_feasible_attribute(obj_att_anno, obj_id)\n",
    "print(feasible_attribute_names)\n",
    "# for a in feasible_attribute_names:\n",
    "#     print(attribute_index_reversed[a])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b4bf4521",
   "metadata": {},
   "source": [
    "### CLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9a838e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c15589",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fab62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_image(model, anno_image, obj_att_anno=False):\n",
    "    object_name = anno_image['object_name']\n",
    "    prompt_template=\"a photo of \"\n",
    "    if obj_att_anno is False:\n",
    "        attribute_object_pairs = [prompt_template + x + ' ' + object_name for x in attribute_index]\n",
    "    else:\n",
    "        feasible_attributes = find_feasible_attribute(obj_att_anno, object_index[object_name])\n",
    "        attribute_object_pairs = [prompt_template + x + ' ' + object_name for x in feasible_attributes]\n",
    "    bbox = anno_image['instance_bbox']\n",
    "    bbox = list(map(int, bbox))\n",
    "    image_path = glob('/data/liangkongming/data/VG/*/{}.jpg'.format(anno_image['image_id']))[0]\n",
    "    image = Image.open(image_path)\n",
    "    image_crop = image.crop((bbox[0], bbox[1], bbox[0] + bbox[2], bbox[1] + bbox[3]))\n",
    "    image = preprocess(image_crop).unsqueeze(0).to(device)\n",
    "    text = clip.tokenize(attribute_object_pairs).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "#         image_features = model.encode_image(image)\n",
    "#         text_features = model.encode_text(text)\n",
    "        logits_per_image, logits_per_text = model(image, text)\n",
    "        probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n",
    "    return image_crop, object_name, probs\n",
    "\n",
    "def find_top_k(input_list, K=5):\n",
    "    index_list = np.argsort(input_list)[-K::]\n",
    "    index_list = index_list[::-1]\n",
    "    return index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20454dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_image.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b4662c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NUM = 1000\n",
    "out_anno_train = []\n",
    "# image_id = np.random.randint(len())\n",
    "for image_id in tqdm(range(len(anno['train']))):\n",
    "    anno_image = anno['train'][image_id]\n",
    "    # print(anno_image['positive_attributes'], anno_image['negative_attributes'])\n",
    "    image_crop, object_name, probs = pred_image(model, anno_image, obj_att_anno)\n",
    "    feasible_attributes = find_feasible_attribute(obj_att_anno, object_index[object_name])\n",
    "    top_attributes = find_top_k(probs[0], K=MAX_NUM)\n",
    "    top_attributes = [feasible_attributes[x] for x in top_attributes]\n",
    "    anno_image['candidate_attributes'] = top_attributes\n",
    "    out_anno_train.append(anno_image)\n",
    "# print(object_name, len(top_attributes), len(feasible_attributes))\n",
    "# print(top_attributes[0:5])\n",
    "# image_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f409eb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_anno_train[0]['candidate_attributes'][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63a713a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = '../data/VAW/data-nidc'\n",
    "with open(osp.join(output_path, 'train.json'), 'w') as f:\n",
    "    json.dump(out_anno_train, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7899ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id = np.random.randint(len(anno['train']))\n",
    "anno_image = anno['train'][image_id]\n",
    "print(anno_image['positive_attributes'], anno_image['negative_attributes'])\n",
    "image_crop, object_name, probs = pred_image(model, anno_image)\n",
    "top_attributes = find_top_k(probs[0], K=5)\n",
    "top_attributes = [attribute_index_reversed[x] for x in top_attributes]\n",
    "print(object_name, top_attributes)\n",
    "image_crop"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ASL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
